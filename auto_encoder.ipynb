{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_excel(\"data/clustered_data.xlsx\", index_col=0)\n",
    "data.drop(\"cluster_labels\", axis=1, inplace=True)\n",
    "data_tensor = torch.tensor(data.values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "train_tensor, val_tensor = train_test_split(data_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(train_tensor)\n",
    "val_dataset = TensorDataset(val_tensor)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedLR(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim):\n",
    "        super(EnhancedLR , self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(x)\n",
    "            return torch.cat((1 - output, output), dim=1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, reconstruction_loss, classification_loss, dropout_rate = 0.15):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.reconstruction_loss = reconstruction_loss\n",
    "        self.classification_loss = classification_loss\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "                nn.Linear(input_dim, 1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(1024, embedding_dim),\n",
    "            )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "                nn.Linear(embedding_dim, 1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1024, input_dim),\n",
    "                nn.Sigmoid(),\n",
    "            )\n",
    "    \n",
    "        self.classifier = EnhancedLR(embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = self.encoder(x)\n",
    "        prediction = self.classifier(x)\n",
    "        return prediction\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        x = self.encoder(x)\n",
    "        predict_proba = self.classifier.predict_proba(x)\n",
    "        return predict_proba\n",
    "    \n",
    "    def unsupervised_train(self, num_epochs, train_dataloader, val_dataloader, optimizer):\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            total_train_loss = 0\n",
    "            \n",
    "            # Training phase\n",
    "            for batch in train_dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                inputs = batch[0].to(self.device)\n",
    "                outputs = self(inputs)\n",
    "                loss = self.reconstruction_loss(outputs, inputs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_train_loss += loss.item()\n",
    "            \n",
    "            # Validation phase\n",
    "            self.eval()\n",
    "            total_val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in val_dataloader:\n",
    "                    inputs = batch[0].to(self.device)\n",
    "                    outputs = self(inputs)\n",
    "                    val_loss = self.reconstruction_loss(outputs, inputs)\n",
    "                    total_val_loss += val_loss.item()\n",
    "\n",
    "            avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "            avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "            \n",
    "            print(f'Epoch: {epoch+1}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}')\n",
    "\n",
    "    def fit(self, num_epochs, train_dataloader, optimizer):\n",
    "        \n",
    "        # L1 Regularization strength\n",
    "        lambda_l1 = 0.2\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            total_train_loss = 0\n",
    "            total_clasification_loss = 0\n",
    "            total_recon_loss = 0\n",
    "            \n",
    "            # Training phase\n",
    "            for inputs, labels in train_dataloader:\n",
    "\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "\n",
    "                #Â Fine-tune the embeddings\n",
    "                reconstruction_loss = self.reconstruction_loss(outputs, inputs)\n",
    "\n",
    "                # Train the classifier \n",
    "                predictions = self.predict(inputs)\n",
    "                classification_loss = self.classification_loss(predictions, labels)\n",
    "\n",
    "                # L1 regularization\n",
    "                l1_reg = torch.tensor(0.)\n",
    "                for param in self.classifier.parameters():\n",
    "                    l1_reg += torch.norm(param, 1)\n",
    "\n",
    "                # Optimize Both \n",
    "                loss = reconstruction_loss + classification_loss +  ( l1_reg * lambda_l1 ) \n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_train_loss += loss.item()\n",
    "                total_clasification_loss = classification_loss.item()\n",
    "                total_recon_loss = reconstruction_loss.item()\n",
    "\n",
    "            avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "            avg_class_loss = total_clasification_loss / len(train_dataloader)\n",
    "            avg_recon_loss = total_recon_loss / len(train_dataloader)\n",
    "            \n",
    "            print(f'Epoch: {epoch+1}, Training Loss: {avg_train_loss}, Recon Loss: {avg_recon_loss}, Classification Loss: {avg_class_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = data.shape[1]\n",
    "embedding_dim = 32\n",
    "\n",
    "reconstruction_loss = nn.BCELoss()\n",
    "classification_loss = nn.BCELoss()\n",
    "\n",
    "model = Autoencoder(input_dim, embedding_dim, reconstruction_loss, classification_loss)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.5202501349978976, Validation Loss: 0.24255972603956857\n",
      "Epoch: 2, Training Loss: 0.22826355530156028, Validation Loss: 0.22056570649147034\n",
      "Epoch: 3, Training Loss: 0.19947504334979588, Validation Loss: 0.1940621038277944\n",
      "Epoch: 4, Training Loss: 0.18265177971786922, Validation Loss: 0.18069389959176382\n",
      "Epoch: 5, Training Loss: 0.17493641045358446, Validation Loss: 0.17681154112021127\n",
      "Epoch: 6, Training Loss: 0.1710172494252523, Validation Loss: 0.17329390347003937\n",
      "Epoch: 7, Training Loss: 0.1666908793979221, Validation Loss: 0.16795764366785684\n",
      "Epoch: 8, Training Loss: 0.16045398844612968, Validation Loss: 0.16116819282372793\n",
      "Epoch: 9, Training Loss: 0.15167764325936636, Validation Loss: 0.1532986064751943\n",
      "Epoch: 10, Training Loss: 0.14495214654339683, Validation Loss: 0.1463757554690043\n"
     ]
    }
   ],
   "source": [
    "model.unsupervised_train(10, train_dataloader, val_dataloader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"auto_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = pd.read_excel(\"data/clustered_data.xlsx\", index_col=0)\n",
    "recipes.drop(\"cluster_labels\", axis=1, inplace=True)\n",
    "data = recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fresh Beans</th>\n",
       "      <th>Tomato</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Salt (Non-Iodized)</th>\n",
       "      <th>Olive Oil</th>\n",
       "      <th>Dried Onion</th>\n",
       "      <th>Potato (in Shell)</th>\n",
       "      <th>Beef (Low Fat)</th>\n",
       "      <th>Charliston Pepper</th>\n",
       "      <th>Tomato Paste</th>\n",
       "      <th>...</th>\n",
       "      <th>Paste Types</th>\n",
       "      <th>Flour Mixture</th>\n",
       "      <th>Sesame</th>\n",
       "      <th>Arugula</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Corn Starch</th>\n",
       "      <th>Fresh Basil</th>\n",
       "      <th>Carbonate</th>\n",
       "      <th>Red Onion</th>\n",
       "      <th>Cherry Tomatoes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1325 rows Ã 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fresh Beans  Tomato  Sugar  Salt (Non-Iodized)  Olive Oil  Dried Onion  \\\n",
       "0               1       1      1                   1          1            1   \n",
       "1               1       1      0                   0          1            0   \n",
       "2               0       1      0                   0          0            0   \n",
       "3               0       1      0                   0          0            1   \n",
       "5               0       0      0                   0          1            1   \n",
       "...           ...     ...    ...                 ...        ...          ...   \n",
       "1924            0       1      0                   1          1            0   \n",
       "1925            1       0      0                   0          0            0   \n",
       "1929            0       0      0                   0          0            0   \n",
       "1930            0       0      0                   0          0            0   \n",
       "1931            0       0      1                   0          0            0   \n",
       "\n",
       "      Potato (in Shell)  Beef (Low Fat)  Charliston Pepper  Tomato Paste  ...  \\\n",
       "0                     0               0                  0             0  ...   \n",
       "1                     1               1                  1             1  ...   \n",
       "2                     0               0                  1             1  ...   \n",
       "3                     0               0                  0             0  ...   \n",
       "5                     0               0                  0             1  ...   \n",
       "...                 ...             ...                ...           ...  ...   \n",
       "1924                  0               0                  0             0  ...   \n",
       "1925                  0               0                  0             0  ...   \n",
       "1929                  0               0                  0             0  ...   \n",
       "1930                  0               0                  0             0  ...   \n",
       "1931                  0               0                  0             0  ...   \n",
       "\n",
       "      Paste Types  Flour Mixture  Sesame  Arugula  Milk  Corn Starch  \\\n",
       "0               0              0       0        0     0            0   \n",
       "1               0              0       0        0     0            0   \n",
       "2               0              0       0        0     0            0   \n",
       "3               0              0       0        0     0            0   \n",
       "5               0              0       0        0     0            0   \n",
       "...           ...            ...     ...      ...   ...          ...   \n",
       "1924            0              0       0        0     0            0   \n",
       "1925            0              0       0        0     0            0   \n",
       "1929            0              0       0        0     0            0   \n",
       "1930            0              0       0        0     0            0   \n",
       "1931            0              0       0        0     0            0   \n",
       "\n",
       "      Fresh Basil  Carbonate  Red Onion  Cherry Tomatoes  \n",
       "0               0          0          0                0  \n",
       "1               0          0          0                0  \n",
       "2               0          0          0                0  \n",
       "3               0          0          0                0  \n",
       "5               0          0          0                0  \n",
       "...           ...        ...        ...              ...  \n",
       "1924            0          0          0                0  \n",
       "1925            0          0          0                0  \n",
       "1929            0          0          0                0  \n",
       "1930            0          0          0                0  \n",
       "1931            0          0          0                0  \n",
       "\n",
       "[1325 rows x 118 columns]"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>recipe</th>\n",
       "      <th>is_accepted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derin</td>\n",
       "      <td>505</td>\n",
       "      <td>{\"CookingTime\": 30, \"Cuisine\": \"World\", \"Ingre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Derin</td>\n",
       "      <td>1699</td>\n",
       "      <td>{\"CookingTime\": 10, \"Cuisine\": \"T\\u00fcrkiye\",...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Derin</td>\n",
       "      <td>435</td>\n",
       "      <td>{\"CookingTime\": 45, \"Cuisine\": \"T\\u00fcrkiye\",...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Derin</td>\n",
       "      <td>583</td>\n",
       "      <td>{\"CookingTime\": 20, \"Cuisine\": \"T\\u00fcrkiye\",...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Derin</td>\n",
       "      <td>1714</td>\n",
       "      <td>{\"CookingTime\": 40, \"Cuisine\": \"T\\u00fcrkiye\",...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Derin</td>\n",
       "      <td>1833</td>\n",
       "      <td>{\"CookingTime\": 30, \"Cuisine\": \"T\\u00fcrkiye\",...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Derin</td>\n",
       "      <td>806</td>\n",
       "      <td>{\"CookingTime\": 15, \"Cuisine\": \"T\\u00fcrkiye\",...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Derin</td>\n",
       "      <td>1597</td>\n",
       "      <td>{\"CookingTime\": 15, \"Cuisine\": \"T\\u00fcrkiye\",...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Derin</td>\n",
       "      <td>900</td>\n",
       "      <td>{\"CookingTime\": 15, \"Cuisine\": \"World\", \"Ingre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Derin</td>\n",
       "      <td>306</td>\n",
       "      <td>{\"CookingTime\": 10, \"Cuisine\": \"T\\u00fcrkiye\",...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Derin</td>\n",
       "      <td>118</td>\n",
       "      <td>{\"CookingTime\": 45, \"Cuisine\": \"T\\u00fcrkiye\",...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Derin</td>\n",
       "      <td>1901</td>\n",
       "      <td>{\"CookingTime\": 45, \"Cuisine\": \"T\\u00fcrkiye\",...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     uuid  recipe_id                                             recipe  \\\n",
       "0   Derin        505  {\"CookingTime\": 30, \"Cuisine\": \"World\", \"Ingre...   \n",
       "1   Derin       1699  {\"CookingTime\": 10, \"Cuisine\": \"T\\u00fcrkiye\",...   \n",
       "2   Derin        435  {\"CookingTime\": 45, \"Cuisine\": \"T\\u00fcrkiye\",...   \n",
       "3   Derin        583  {\"CookingTime\": 20, \"Cuisine\": \"T\\u00fcrkiye\",...   \n",
       "4   Derin       1714  {\"CookingTime\": 40, \"Cuisine\": \"T\\u00fcrkiye\",...   \n",
       "5   Derin       1833  {\"CookingTime\": 30, \"Cuisine\": \"T\\u00fcrkiye\",...   \n",
       "6   Derin        806  {\"CookingTime\": 15, \"Cuisine\": \"T\\u00fcrkiye\",...   \n",
       "7   Derin       1597  {\"CookingTime\": 15, \"Cuisine\": \"T\\u00fcrkiye\",...   \n",
       "8   Derin        900  {\"CookingTime\": 15, \"Cuisine\": \"World\", \"Ingre...   \n",
       "12  Derin        306  {\"CookingTime\": 10, \"Cuisine\": \"T\\u00fcrkiye\",...   \n",
       "13  Derin        118  {\"CookingTime\": 45, \"Cuisine\": \"T\\u00fcrkiye\",...   \n",
       "14  Derin       1901  {\"CookingTime\": 45, \"Cuisine\": \"T\\u00fcrkiye\",...   \n",
       "\n",
       "    is_accepted  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             0  \n",
       "4             1  \n",
       "5             0  \n",
       "6             0  \n",
       "7             0  \n",
       "8             1  \n",
       "12            0  \n",
       "13            1  \n",
       "14            0  "
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_excel(\"data/recipe_logs.xlsx\", index_col=0)\n",
    "test_set.drop(\"id\", axis=1, inplace=True)\n",
    "users_feedback = test_set\n",
    "users_feedback = users_feedback[users_feedback.uuid == \"Derin\"]\n",
    "labels = users_feedback.is_accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_feedback = users_feedback[users_feedback.uuid == \"Derin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = recipes.loc[users_feedback.recipe_id.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(recipes, labels, test_size=0.60, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.index = X_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1) \n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = recipes.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_LR = LogisticRegression(penalty='l2', C=0.1, n_jobs=-1, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.7295981645584106, Recon Loss: 0.0795564353466034, Classification Loss: 0.21470609307289124\n",
      "Epoch: 2, Training Loss: 0.6816551089286804, Recon Loss: 0.07532789558172226, Classification Loss: 0.17653021216392517\n",
      "Epoch: 3, Training Loss: 0.6428464651107788, Recon Loss: 0.07159875333309174, Classification Loss: 0.14710985124111176\n",
      "Epoch: 4, Training Loss: 0.6092850565910339, Recon Loss: 0.06737720966339111, Classification Loss: 0.12352975457906723\n",
      "Epoch: 5, Training Loss: 0.5784178972244263, Recon Loss: 0.058660365641117096, Classification Loss: 0.10706464946269989\n"
     ]
    }
   ],
   "source": [
    "simple_LR.fit(X_train,y_train)\n",
    "model.fit(5,dataloader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor(X_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict(X_test).detach()\n",
    "labels = (probabilities >= 0.5).float().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score( labels , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
