{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from pytorch_metric_learning.losses import NTXentLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLearning(torch.nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, projection_dim, dropout_rate=0.15):\n",
    "        super(ContrastiveLearning, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "                nn.Linear(input_dim, 2056),\n",
    "                nn.BatchNorm1d(2056),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(2056, 1028),\n",
    "                nn.BatchNorm1d(1028),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(1028, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(512, embedding_dim),\n",
    "            )\n",
    "\n",
    "        self.projector = nn.Sequential(\n",
    "                nn.Linear(embedding_dim, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(256, 128),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(128, projection_dim),\n",
    "            )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedding = self.encoder(x)\n",
    "        projection = self.projector(embedding)\n",
    "        return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = NTXentLoss(temperature=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel(\"data/synthetic_dataset.xlsx\", index_col=0)\n",
    "cluster_labels = pd.read_excel(\"data/clusters.xlsx\", index_col=0)\n",
    "cluster_labels.index = data.index\n",
    "cluster_labels = cluster_labels[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_dim = data.shape[1]\n",
    "embedding_dim = 32\n",
    "projection_dim = 8\n",
    "\n",
    "model = ContrastiveLearning(input_dim, embedding_dim, projection_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterContrastiveDataset(Dataset):\n",
    "    def __init__(self, data, cluster_labels):\n",
    "        self.data = data\n",
    "        self.cluster_labels = cluster_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        label = self.cluster_labels.iloc[idx]\n",
    "        positive_indices = [i for i, same_label in enumerate(self.cluster_labels) if same_label == label and i != idx]\n",
    "        positive_idx = random.choice(positive_indices)\n",
    "        positive_item = self.data.iloc[positive_idx]\n",
    "\n",
    "        item_tensor = torch.tensor(item, dtype=torch.float32)\n",
    "        positive_item_tensor = torch.tensor(positive_item, dtype=torch.float32)\n",
    "\n",
    "\n",
    "        return item_tensor, positive_item_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ClusterContrastiveDataset(data=data, cluster_labels=cluster_labels)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=512, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, log_interval): \n",
    "\n",
    "   for epoch in range(num_epochs):\n",
    "        model.train()  \n",
    "        total_loss = 0\n",
    "\n",
    "        for batch_idx, (data_i, data_j) in enumerate(dataloader):\n",
    "\n",
    "            data_i, data_j = data_i.float().to(device), data_j.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "\n",
    "            projections_i = model(data_i)\n",
    "            projections_j = model(data_j)\n",
    "\n",
    "            # Concatenate the projections: \n",
    "            # The positive pairs are adjacent to each other, and all others are considered negatives.\n",
    "            projections = torch.cat([projections_i, projections_j], dim=0)\n",
    "            \n",
    "            batch_size = projections_i.size(0)\n",
    "            labels = torch.arange(batch_size, dtype=torch.long).to(device)\n",
    "            labels = torch.cat((labels, labels), dim=0)  # Duplicate labels for both halves of concatenated data\n",
    "\n",
    "            # Calculate the contrastive loss\n",
    "            loss = criterion(projections, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Convert the Pandas series to a tensor and add an extra batch dimension\n",
    "single_sample = torch.tensor(dataset.data.iloc[100].values).float().unsqueeze(0)\n",
    "\n",
    "model.encoder(single_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finch import FINCH\n",
    "\n",
    "embeddings = model.encoder(torch.tensor(dataset.data.values).float()).detach()\n",
    "\n",
    "if embeddings.is_cuda:\n",
    "    embeddings = embeddings.cpu()\n",
    "\n",
    "embeddings_np = embeddings.numpy()\n",
    "\n",
    "c, num_clust, req_c = FINCH(embeddings_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clusters =  pd.DataFrame(c)[4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "ari_score = adjusted_rand_score(cluster_labels.values, new_clusters)\n",
    "nmi_score = normalized_mutual_info_score( cluster_labels.values, new_clusters)\n",
    "\n",
    "print(\"Adjusted Rand Index:\", ari_score)\n",
    "print(\"Normalized Mutual Information:\", nmi_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(embeddings, index = cluster_labels.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'embeddings' is a numpy array of your data embeddings\n",
    "# And 'cluster_labels' is an array of cluster labels corresponding to each point in 'embeddings'\n",
    "embeddings_2d = TSNE(n_components=2, random_state=0).fit_transform(embeddings)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=new_clusters, cmap='viridis', alpha=0.5)\n",
    "plt.colorbar()  # To show the color scale\n",
    "plt.title('t-SNE plot of the embeddings colored by cluster label')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_excel(\"data/synthetic_dataset.xlsx\", index_col=0)\n",
    "embeddings_2d = TSNE(n_components=2, random_state=0).fit_transform(data)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=cluster_labels, cmap='viridis', alpha=0.5)\n",
    "plt.colorbar()  # To show the color scale\n",
    "plt.title('t-SNE plot of the actual data')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = pd.read_excel(\"data/clustered_data.xlsx\", index_col=0)\n",
    "recipes.drop(\"cluster_labels\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_excel(\"data/recipe_logs.xlsx\", index_col=0)\n",
    "test_set.drop(\"id\", axis=1, inplace=True)\n",
    "users_feedback = test_set\n",
    "labels = users_feedback.is_accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = recipes.loc[users_feedback.recipe_id.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(recipes, labels, test_size=0.20, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_LR = LogisticRegression(penalty='l2', C=0.1, n_jobs=-1, max_iter=1000)\n",
    "contastive_LR = LogisticRegression(penalty='l2', C=0.1, n_jobs=-1, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_LR.fit(X_train,y_train)\n",
    "embeddings = model.encoder(torch.tensor(X_train.values).float()).detach()\n",
    "embedding_test = model.encoder(torch.tensor(X_test.values).float()).detach()\n",
    "contastive_LR.fit(embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_LR.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contastive_LR.score(embeddings,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_LR.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contastive_LR.predict(embeddings).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_LR.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contastive_LR.score(embedding_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
