{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from pytorch_metric_learning.losses import NTXentLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLearning(torch.nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, projection_dim, dropout_rate=0.25):\n",
    "        super(ContrastiveLearning, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "                nn.Linear(input_dim, 1028),\n",
    "                nn.BatchNorm1d(1028),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(1028, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(512, embedding_dim),\n",
    "            )\n",
    "\n",
    "        self.projector = nn.Sequential(\n",
    "                nn.Linear(embedding_dim, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(256, projection_dim),\n",
    "            )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedding = self.encoder(x)\n",
    "        projection = self.projector(embedding)\n",
    "        return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = NTXentLoss(temperature=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_excel(\"data/clustered_data.xlsx\", index_col=0)\n",
    "cluster_labels = dataset.cluster_labels\n",
    "dataset.drop(\"cluster_labels\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_dim = dataset.shape[1]\n",
    "embedding_dim = 32\n",
    "projection_dim = 8\n",
    "\n",
    "model = ContrastiveLearning(input_dim, embedding_dim, projection_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterContrastiveDataset(Dataset):\n",
    "    def __init__(self, data, cluster_labels):\n",
    "        self.data = data\n",
    "        self.cluster_labels = cluster_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        label = self.cluster_labels.iloc[idx]\n",
    "        positive_indices = [i for i, same_label in enumerate(self.cluster_labels) if same_label == label and i != idx]\n",
    "        positive_idx = random.choice(positive_indices)\n",
    "        positive_item = self.data.iloc[positive_idx]\n",
    "\n",
    "        item_tensor = torch.tensor(item, dtype=torch.float32)\n",
    "        positive_item_tensor = torch.tensor(positive_item, dtype=torch.float32)\n",
    "\n",
    "\n",
    "        return item_tensor, positive_item_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ClusterContrastiveDataset(data=dataset, cluster_labels=cluster_labels)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, log_interval): \n",
    "\n",
    "   for epoch in range(num_epochs):\n",
    "        model.train()  \n",
    "        total_loss = 0\n",
    "\n",
    "        for batch_idx, (data_i, data_j) in enumerate(dataloader):\n",
    "\n",
    "            data_i, data_j = data_i.float().to(device), data_j.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "\n",
    "            projections_i = model(data_i)\n",
    "            projections_j = model(data_j)\n",
    "\n",
    "            # Concatenate the projections: \n",
    "            # The positive pairs are adjacent to each other, and all others are considered negatives.\n",
    "            projections = torch.cat([projections_i, projections_j], dim=0)\n",
    "            \n",
    "            batch_size = projections_i.size(0)\n",
    "            labels = torch.arange(batch_size, dtype=torch.long).to(device)\n",
    "            labels = torch.cat((labels, labels), dim=0)  # Duplicate labels for both halves of concatenated data\n",
    "\n",
    "            # Calculate the contrastive loss\n",
    "            loss = criterion(projections, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(20,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Convert the Pandas series to a tensor and add an extra batch dimension\n",
    "single_sample = torch.tensor(dataset.data.iloc[100].values).float().unsqueeze(0)\n",
    "\n",
    "model.encoder(single_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
